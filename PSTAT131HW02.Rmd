---
title: "PSTAT131HW02"
author: "Yifei Zhang"
date: '2022-04-10'
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
```{r include=FALSE}
library(ggplot2)
library(tidyverse)
library(tidymodels)
library(corrplot)
library(ggthemes)
library(yardstick)
tidymodels_prefer()
```
### Question 1

Your goal is to predict abalone age, which is calculated as the number of rings plus 1.5. Notice there currently is no `age` variable in the data set. Add `age` to the data set.

```{r echo=TRUE}
abalone <- read.csv("abalone.csv")

new_abalone <- abalone %>% 
  mutate(age = rings + 1.5)

```

Assess and describe the distribution of `age`.

As we access the distribution of the new variable age, we can see it looks relatively normal, but is skewed a bit to the right, centering around 10. 

```{r echo=TRUE}
new_abalone %>%
  ggplot(aes(x = age)) +
  geom_histogram(bins = 50) +
  theme_bw()
```

### Question 2

Split the abalone data into a training set and a testing set. Use stratified sampling. You should decide on appropriate percentages for splitting the data.

*Remember that you'll need to set a seed at the beginning of the document to reproduce your results.*

```{r echo=TRUE}
set.seed(710)

#I need to put the above lines of code there so I dont run 
#into problems later when knitting, its a logical error if 
#I dont put them there. Because splitting the training and 
#test data before dummy coding type will result in them not 
#having the new variable.

abalone_split <- initial_split(new_abalone, prop = 0.80,
                                strata = age)

abalone_train <- training(abalone_split)

abalone_test <- testing(abalone_split)
abalone_train %>% 
  head()
```

                              
### Question 3

Using the **training** data, create a recipe predicting the outcome variable, `age`, with all other predictor variables. Note that you should not include `rings` to predict `age`. Explain why you shouldn't use `rings` to predict `age`.

I should not use rings to predict age, because we have used rings to calculate age in step 1, and we wont be able to see how other predictors can predict by having rings as one of the predictors, since we already have age = rings + 1.5 function.

Steps for your recipe:

1.  dummy code any categorical predictors

new_abalone$gender_m <- ifelse(new_abalone$type == "M", 1, 0)  

new_abalone$gender_f <- ifelse(new_abalone$type == "F", 1, 0) 

new_abalone$gender_i <- ifelse(new_abalone$type == "I", 1, 0)  


this don't seem to work with the latter steps

```{r echo=FALSE}

# or use step_dummy()

sapply(new_abalone, class)
```

2.  create interactions between

    -   `type` and `shucked_weight`,
    -   `longest_shell` and `diameter`,
    -   `shucked_weight` and `shell_weight`


3.  center all predictors, and


4.  scale all predictors.

You'll need to investigate the `tidymodels` documentation to find the appropriate step functions to use.



Creating recipe

```{r }
new_abalone %>%
  head()
abalone_recipe <- recipe(age ~ longest_shell + diameter + height +
                           whole_weight + shucked_weight +
                           viscera_weight + shell_weight + type,
                         data = new_abalone) %>%
  step_dummy(all_nominal_predictors()) %>% 
  step_center(longest_shell, diameter, height, whole_weight,
              shucked_weight, viscera_weight, shell_weight
              ) %>%
  step_scale(longest_shell, diameter, height, whole_weight,
              shucked_weight, viscera_weight, shell_weight
              ) %>%
  step_interact(terms = ~ type : shucked_weight) %>% 
  step_interact(terms = ~ longest_shell : diameter) %>% 
  step_interact(terms = ~ shell_weight : shucked_weight) 

abalone_recipe
```
%>%  
  prep(abalone_train)

### Question 4

Create and store a linear regression object using the `"lm"` engine.

```{r }
lm_model <- linear_reg() %>% 
  set_engine("lm")

# I ended up using what we used in the lab, but what is the difference?

fit <- lm(age ~ longest_shell + diameter + height +
                           whole_weight + shucked_weight +
                           viscera_weight + shell_weight + type,
                         data = new_abalone)
summary(fit)
summary(lm_model)
```


### Question 5

Now:

1.  set up an empty workflow,
2.  add the model you created in Question 4, and
3.  add the recipe that you created in Question 3.

```{r }
lm_wflow <- workflow() %>% 
  add_model(lm_model) %>% 
  add_recipe(abalone_recipe)

lm_wflow
```

### Question 6

Use your `fit()` object to predict the age of a hypothetical female abalone with longest_shell = 0.50, diameter = 0.10, height = 0.30, whole_weight = 4, shucked_weight = 1, viscera_weight = 2, shell_weight = 1.

```{r }
lm_fit <- fit(lm_wflow, abalone_train)

test <- data.frame(longest_shell = 0.50,
                   diameter = 0.10,
                   height =0.30,
                   whole_weight = 4,
                   shucked_weight = 1,
                   viscera_weight = 2,
                   shell_weight = 1,
                   type = "F")

lm_fit %>% 
  extract_fit_parsnip() %>% 
  tidy()

predict(lm_fit, new_data = test)
lm_fit
```

### Question 7

Now you want to assess your model's performance. To do this, use the `yardstick` package:

1.  Create a metric set that includes *R^2^*, RMSE (root mean squared error), and MAE (mean absolute error).
2.  Use `predict()` and `bind_cols()` to create a tibble of your model's predicted values from the **training data** along with the actual observed ages (these are needed to assess your model's performance).
3.  Finally, apply your metric set to the tibble, report the results, and interpret the *R^2^* value.

From what we got for *R^2^* which is roughly 0.55, it is not significant enough to show a strong correlation, it can only be considered relatively strong, but it is not significant enough to compare with our initial function which is age = rings + 1.5. Though the question didn't require us to plot a graph, but the scatter plot should be a clear visual representation that our model didn't do well. 

```{r }
abalone_train %>% 
  head()
abalone_train_res <- predict(lm_fit, new_data = abalone_train %>%
                               select(-age, -rings))

abalone_train_res %>% 
  head()

abalone_train_res <- bind_cols(abalone_train_res, abalone_train %>% select(age))

abalone_train_res %>% 
  head()

rmse(abalone_train_res, truth = age, estimate = .pred)

abalone_metrics <- metric_set(rmse, rsq, mae)

abalone_metrics(abalone_train_res, truth = age, 
                estimate = .pred)

abalone_train_res %>% 
  ggplot(aes(x = .pred, y = age)) +
  geom_point(alpha = 0.2) +
  geom_abline(lty = 2) + 
  theme_bw() +
  coord_obs_pred()
```

